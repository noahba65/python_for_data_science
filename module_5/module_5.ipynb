{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noah Anderson   \n",
    "Module 5  \n",
    "July 5th, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import stats \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in baseball players data\n",
    "players = pd.read_csv(\"hall_of_fame.csv\")\n",
    "\n",
    "# Create singles column\n",
    "players['singles'] = players['hits'] - players['doubles'] - players['triples'] - players['HR']\n",
    "\n",
    "# Create data frame selecting only hitting related data\n",
    "hitting_df = (players[['runs', 'AB', 'singles', 'doubles', 'triples', 'HR', 'BB', 'SO']]\n",
    "              .dropna()) # Drop NA's\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>runs</td>       <th>  R-squared:         </th> <td>   0.949</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.949</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4098.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 25 Jun 2024</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:10:28</td>     <th>  Log-Likelihood:    </th> <td> -7739.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1320</td>      <th>  AIC:               </th> <td>1.549e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1313</td>      <th>  BIC:               </th> <td>1.553e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  -24.6262</td> <td>    6.536</td> <td>   -3.768</td> <td> 0.000</td> <td>  -37.449</td> <td>  -11.803</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>singles</th>   <td>    0.3875</td> <td>    0.013</td> <td>   28.858</td> <td> 0.000</td> <td>    0.361</td> <td>    0.414</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>doubles</th>   <td>   -0.0375</td> <td>    0.058</td> <td>   -0.649</td> <td> 0.517</td> <td>   -0.151</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>triples</th>   <td>    2.5550</td> <td>    0.097</td> <td>   26.455</td> <td> 0.000</td> <td>    2.366</td> <td>    2.744</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HR</th>        <td>    0.6610</td> <td>    0.038</td> <td>   17.206</td> <td> 0.000</td> <td>    0.586</td> <td>    0.736</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BB</th>        <td>    0.3230</td> <td>    0.014</td> <td>   23.216</td> <td> 0.000</td> <td>    0.296</td> <td>    0.350</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SO</th>        <td>   -0.0417</td> <td>    0.013</td> <td>   -3.329</td> <td> 0.001</td> <td>   -0.066</td> <td>   -0.017</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>263.662</td> <th>  Durbin-Watson:     </th> <td>   2.002</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1342.745</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.834</td>  <th>  Prob(JB):          </th> <td>2.67e-292</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 7.651</td>  <th>  Cond. No.          </th> <td>3.36e+03</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.36e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       runs       & \\textbf{  R-squared:         } &     0.949   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.949   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     4098.   \\\\\n",
       "\\textbf{Date:}             & Tue, 25 Jun 2024 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}             &     10:10:28     & \\textbf{  Log-Likelihood:    } &   -7739.6   \\\\\n",
       "\\textbf{No. Observations:} &        1320      & \\textbf{  AIC:               } & 1.549e+04   \\\\\n",
       "\\textbf{Df Residuals:}     &        1313      & \\textbf{  BIC:               } & 1.553e+04   \\\\\n",
       "\\textbf{Df Model:}         &           6      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &     -24.6262  &        6.536     &    -3.768  &         0.000        &      -37.449    &      -11.803     \\\\\n",
       "\\textbf{singles}   &       0.3875  &        0.013     &    28.858  &         0.000        &        0.361    &        0.414     \\\\\n",
       "\\textbf{doubles}   &      -0.0375  &        0.058     &    -0.649  &         0.517        &       -0.151    &        0.076     \\\\\n",
       "\\textbf{triples}   &       2.5550  &        0.097     &    26.455  &         0.000        &        2.366    &        2.744     \\\\\n",
       "\\textbf{HR}        &       0.6610  &        0.038     &    17.206  &         0.000        &        0.586    &        0.736     \\\\\n",
       "\\textbf{BB}        &       0.3230  &        0.014     &    23.216  &         0.000        &        0.296    &        0.350     \\\\\n",
       "\\textbf{SO}        &      -0.0417  &        0.013     &    -3.329  &         0.001        &       -0.066    &       -0.017     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 263.662 & \\textbf{  Durbin-Watson:     } &     2.002  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } &  1342.745  \\\\\n",
       "\\textbf{Skew:}          &   0.834 & \\textbf{  Prob(JB):          } & 2.67e-292  \\\\\n",
       "\\textbf{Kurtosis:}      &   7.651 & \\textbf{  Cond. No.          } &  3.36e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 3.36e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   runs   R-squared:                       0.949\n",
       "Model:                            OLS   Adj. R-squared:                  0.949\n",
       "Method:                 Least Squares   F-statistic:                     4098.\n",
       "Date:                Tue, 25 Jun 2024   Prob (F-statistic):               0.00\n",
       "Time:                        10:10:28   Log-Likelihood:                -7739.6\n",
       "No. Observations:                1320   AIC:                         1.549e+04\n",
       "Df Residuals:                    1313   BIC:                         1.553e+04\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    -24.6262      6.536     -3.768      0.000     -37.449     -11.803\n",
       "singles        0.3875      0.013     28.858      0.000       0.361       0.414\n",
       "doubles       -0.0375      0.058     -0.649      0.517      -0.151       0.076\n",
       "triples        2.5550      0.097     26.455      0.000       2.366       2.744\n",
       "HR             0.6610      0.038     17.206      0.000       0.586       0.736\n",
       "BB             0.3230      0.014     23.216      0.000       0.296       0.350\n",
       "SO            -0.0417      0.013     -3.329      0.001      -0.066      -0.017\n",
       "==============================================================================\n",
       "Omnibus:                      263.662   Durbin-Watson:                   2.002\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1342.745\n",
       "Skew:                           0.834   Prob(JB):                    2.67e-292\n",
       "Kurtosis:                       7.651   Cond. No.                     3.36e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.36e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit linear model for runs using hitting variables\n",
    "model1 = smf.ols('runs ~ singles + doubles + triples + HR + BB + SO', \n",
    "                 data = hitting_df).fit()\n",
    "\n",
    "# Summarize model\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c.\n",
    " The R squared stasitic explains the percentage of variation explained by the model. The adjusted R squared for this model is .949 which is considerably high indicating that this likely fits the model well. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d. \n",
    "The relationship of the doubles coeffecient being slightly negative is counterintiutive. One explanation is that it is close to zero, but slightly negative with a non-significant p-value of .517 implying that there is low confidence in this relationship with runs. Additionally it feels wrong to include home runs since in theory this should be a 1-to-1 ratio since scoring a homerun results in run by definition. The relationship of .6610 is less than I would expect. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a.\n",
    "At-bats are closely related to other hitting statistics because more at-bats provide more opportunities to accumulate these statistics. For instance, an average player who has played five times longer than an excellent player will naturally have more at-bats, resulting in a higher accumulation of hitting statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>runs</th>\n",
       "      <th>AB</th>\n",
       "      <th>singles</th>\n",
       "      <th>doubles</th>\n",
       "      <th>triples</th>\n",
       "      <th>HR</th>\n",
       "      <th>BB</th>\n",
       "      <th>SO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>runs</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.930846</td>\n",
       "      <td>0.921744</td>\n",
       "      <td>0.899165</td>\n",
       "      <td>0.785519</td>\n",
       "      <td>0.562797</td>\n",
       "      <td>0.827109</td>\n",
       "      <td>0.059733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AB</th>\n",
       "      <td>0.930846</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966941</td>\n",
       "      <td>0.925077</td>\n",
       "      <td>0.707119</td>\n",
       "      <td>0.560482</td>\n",
       "      <td>0.776491</td>\n",
       "      <td>0.122526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>singles</th>\n",
       "      <td>0.921744</td>\n",
       "      <td>0.966941</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896605</td>\n",
       "      <td>0.767146</td>\n",
       "      <td>0.396568</td>\n",
       "      <td>0.704995</td>\n",
       "      <td>0.069465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doubles</th>\n",
       "      <td>0.899165</td>\n",
       "      <td>0.925077</td>\n",
       "      <td>0.896605</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.712002</td>\n",
       "      <td>0.585208</td>\n",
       "      <td>0.751428</td>\n",
       "      <td>0.125205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>triples</th>\n",
       "      <td>0.785519</td>\n",
       "      <td>0.707119</td>\n",
       "      <td>0.767146</td>\n",
       "      <td>0.712002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.160062</td>\n",
       "      <td>0.493767</td>\n",
       "      <td>-0.010294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HR</th>\n",
       "      <td>0.562797</td>\n",
       "      <td>0.560482</td>\n",
       "      <td>0.396568</td>\n",
       "      <td>0.585208</td>\n",
       "      <td>0.160062</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.663796</td>\n",
       "      <td>0.125668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BB</th>\n",
       "      <td>0.827109</td>\n",
       "      <td>0.776491</td>\n",
       "      <td>0.704995</td>\n",
       "      <td>0.751428</td>\n",
       "      <td>0.493767</td>\n",
       "      <td>0.663796</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.120935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SO</th>\n",
       "      <td>0.059733</td>\n",
       "      <td>0.122526</td>\n",
       "      <td>0.069465</td>\n",
       "      <td>0.125205</td>\n",
       "      <td>-0.010294</td>\n",
       "      <td>0.125668</td>\n",
       "      <td>0.120935</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             runs        AB   singles   doubles   triples        HR        BB  \\\n",
       "runs     1.000000  0.930846  0.921744  0.899165  0.785519  0.562797  0.827109   \n",
       "AB       0.930846  1.000000  0.966941  0.925077  0.707119  0.560482  0.776491   \n",
       "singles  0.921744  0.966941  1.000000  0.896605  0.767146  0.396568  0.704995   \n",
       "doubles  0.899165  0.925077  0.896605  1.000000  0.712002  0.585208  0.751428   \n",
       "triples  0.785519  0.707119  0.767146  0.712002  1.000000  0.160062  0.493767   \n",
       "HR       0.562797  0.560482  0.396568  0.585208  0.160062  1.000000  0.663796   \n",
       "BB       0.827109  0.776491  0.704995  0.751428  0.493767  0.663796  1.000000   \n",
       "SO       0.059733  0.122526  0.069465  0.125205 -0.010294  0.125668  0.120935   \n",
       "\n",
       "               SO  \n",
       "runs     0.059733  \n",
       "AB       0.122526  \n",
       "singles  0.069465  \n",
       "doubles  0.125205  \n",
       "triples -0.010294  \n",
       "HR       0.125668  \n",
       "BB       0.120935  \n",
       "SO       1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set options so that the entire correlation matrix is printed\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Show correlation matrix for hitting data\n",
    "hitting_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At-bats are highly correlated with positive hitting statistics, with the exception of strikeouts. The correlation with home runs is the weakest among these, with a value of 0.56. Singles are highly correlated at .97 which makes sense considering it is the most achievable out of the types of hits (singles, doubles, triples, and home runs).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>runs</td>       <th>  R-squared:         </th> <td>   0.866</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.866</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   8553.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 25 Jun 2024</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:10:29</td>     <th>  Log-Likelihood:    </th> <td> -8378.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1320</td>      <th>  AIC:               </th> <td>1.676e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1318</td>      <th>  BIC:               </th> <td>1.677e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> -122.9048</td> <td>    9.047</td> <td>  -13.585</td> <td> 0.000</td> <td> -140.653</td> <td> -105.156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AB</th>        <td>    0.1672</td> <td>    0.002</td> <td>   92.481</td> <td> 0.000</td> <td>    0.164</td> <td>    0.171</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>305.818</td> <th>  Durbin-Watson:     </th> <td>   2.068</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1220.021</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.061</td>  <th>  Prob(JB):          </th> <td>1.19e-265</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 7.205</td>  <th>  Cond. No.          </th> <td>1.19e+04</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.19e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       runs       & \\textbf{  R-squared:         } &     0.866   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.866   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     8553.   \\\\\n",
       "\\textbf{Date:}             & Tue, 25 Jun 2024 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}             &     10:10:29     & \\textbf{  Log-Likelihood:    } &   -8378.9   \\\\\n",
       "\\textbf{No. Observations:} &        1320      & \\textbf{  AIC:               } & 1.676e+04   \\\\\n",
       "\\textbf{Df Residuals:}     &        1318      & \\textbf{  BIC:               } & 1.677e+04   \\\\\n",
       "\\textbf{Df Model:}         &           1      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &    -122.9048  &        9.047     &   -13.585  &         0.000        &     -140.653    &     -105.156     \\\\\n",
       "\\textbf{AB}        &       0.1672  &        0.002     &    92.481  &         0.000        &        0.164    &        0.171     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 305.818 & \\textbf{  Durbin-Watson:     } &     2.068  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } &  1220.021  \\\\\n",
       "\\textbf{Skew:}          &   1.061 & \\textbf{  Prob(JB):          } & 1.19e-265  \\\\\n",
       "\\textbf{Kurtosis:}      &   7.205 & \\textbf{  Cond. No.          } &  1.19e+04  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.19e+04. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   runs   R-squared:                       0.866\n",
       "Model:                            OLS   Adj. R-squared:                  0.866\n",
       "Method:                 Least Squares   F-statistic:                     8553.\n",
       "Date:                Tue, 25 Jun 2024   Prob (F-statistic):               0.00\n",
       "Time:                        10:10:29   Log-Likelihood:                -8378.9\n",
       "No. Observations:                1320   AIC:                         1.676e+04\n",
       "Df Residuals:                    1318   BIC:                         1.677e+04\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   -122.9048      9.047    -13.585      0.000    -140.653    -105.156\n",
       "AB             0.1672      0.002     92.481      0.000       0.164       0.171\n",
       "==============================================================================\n",
       "Omnibus:                      305.818   Durbin-Watson:                   2.068\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1220.021\n",
       "Skew:                           1.061   Prob(JB):                    1.19e-265\n",
       "Kurtosis:                       7.205   Cond. No.                     1.19e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.19e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model for runs using only at-bats as a predictor\n",
    "model2 = smf.ols('runs ~ AB', data = hitting_df).fit()\n",
    "\n",
    "# Show summary of at-bats model\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R-squared value for this model is 0.866, indicating that it is quite effective at explaining the variance in runs based on at-bats. This value is only 0.093 lower than the R-squared for the first model. However, the apparent predictive power of the more inclusive model may be misleading due to multicollinearity, which will be explored in the next question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create per-at-bats data frame\n",
    "hitting_rates_df = (hitting_df\n",
    "                    .drop(columns = 'AB')\n",
    "                    .div(hitting_df['AB'], axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>runs</td>       <th>  R-squared:         </th> <td>   0.643</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.641</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   393.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 25 Jun 2024</td> <th>  Prob (F-statistic):</th> <td>4.73e-289</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:10:29</td>     <th>  Log-Likelihood:    </th> <td>  3424.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1320</td>      <th>  AIC:               </th> <td>  -6834.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1313</td>      <th>  BIC:               </th> <td>  -6798.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -0.0358</td> <td>    0.006</td> <td>   -5.587</td> <td> 0.000</td> <td>   -0.048</td> <td>   -0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>singles</th>   <td>    0.4840</td> <td>    0.030</td> <td>   16.133</td> <td> 0.000</td> <td>    0.425</td> <td>    0.543</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>doubles</th>   <td>    0.0941</td> <td>    0.063</td> <td>    1.494</td> <td> 0.135</td> <td>   -0.029</td> <td>    0.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>triples</th>   <td>    2.7476</td> <td>    0.105</td> <td>   26.142</td> <td> 0.000</td> <td>    2.541</td> <td>    2.954</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HR</th>        <td>    0.7909</td> <td>    0.049</td> <td>   16.245</td> <td> 0.000</td> <td>    0.695</td> <td>    0.886</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BB</th>        <td>    0.3036</td> <td>    0.015</td> <td>   20.124</td> <td> 0.000</td> <td>    0.274</td> <td>    0.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SO</th>        <td>   -0.0217</td> <td>    0.006</td> <td>   -3.553</td> <td> 0.000</td> <td>   -0.034</td> <td>   -0.010</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>102.098</td> <th>  Durbin-Watson:     </th> <td>   1.967</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 197.493</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.515</td>  <th>  Prob(JB):          </th> <td>1.30e-43</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.590</td>  <th>  Cond. No.          </th> <td>    223.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       runs       & \\textbf{  R-squared:         } &     0.643   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.641   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     393.3   \\\\\n",
       "\\textbf{Date:}             & Tue, 25 Jun 2024 & \\textbf{  Prob (F-statistic):} & 4.73e-289   \\\\\n",
       "\\textbf{Time:}             &     10:10:29     & \\textbf{  Log-Likelihood:    } &    3424.2   \\\\\n",
       "\\textbf{No. Observations:} &        1320      & \\textbf{  AIC:               } &    -6834.   \\\\\n",
       "\\textbf{Df Residuals:}     &        1313      & \\textbf{  BIC:               } &    -6798.   \\\\\n",
       "\\textbf{Df Model:}         &           6      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &      -0.0358  &        0.006     &    -5.587  &         0.000        &       -0.048    &       -0.023     \\\\\n",
       "\\textbf{singles}   &       0.4840  &        0.030     &    16.133  &         0.000        &        0.425    &        0.543     \\\\\n",
       "\\textbf{doubles}   &       0.0941  &        0.063     &     1.494  &         0.135        &       -0.029    &        0.218     \\\\\n",
       "\\textbf{triples}   &       2.7476  &        0.105     &    26.142  &         0.000        &        2.541    &        2.954     \\\\\n",
       "\\textbf{HR}        &       0.7909  &        0.049     &    16.245  &         0.000        &        0.695    &        0.886     \\\\\n",
       "\\textbf{BB}        &       0.3036  &        0.015     &    20.124  &         0.000        &        0.274    &        0.333     \\\\\n",
       "\\textbf{SO}        &      -0.0217  &        0.006     &    -3.553  &         0.000        &       -0.034    &       -0.010     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 102.098 & \\textbf{  Durbin-Watson:     } &    1.967  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } &  197.493  \\\\\n",
       "\\textbf{Skew:}          &   0.515 & \\textbf{  Prob(JB):          } & 1.30e-43  \\\\\n",
       "\\textbf{Kurtosis:}      &   4.590 & \\textbf{  Cond. No.          } &     223.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   runs   R-squared:                       0.643\n",
       "Model:                            OLS   Adj. R-squared:                  0.641\n",
       "Method:                 Least Squares   F-statistic:                     393.3\n",
       "Date:                Tue, 25 Jun 2024   Prob (F-statistic):          4.73e-289\n",
       "Time:                        10:10:29   Log-Likelihood:                 3424.2\n",
       "No. Observations:                1320   AIC:                            -6834.\n",
       "Df Residuals:                    1313   BIC:                            -6798.\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -0.0358      0.006     -5.587      0.000      -0.048      -0.023\n",
       "singles        0.4840      0.030     16.133      0.000       0.425       0.543\n",
       "doubles        0.0941      0.063      1.494      0.135      -0.029       0.218\n",
       "triples        2.7476      0.105     26.142      0.000       2.541       2.954\n",
       "HR             0.7909      0.049     16.245      0.000       0.695       0.886\n",
       "BB             0.3036      0.015     20.124      0.000       0.274       0.333\n",
       "SO            -0.0217      0.006     -3.553      0.000      -0.034      -0.010\n",
       "==============================================================================\n",
       "Omnibus:                      102.098   Durbin-Watson:                   1.967\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              197.493\n",
       "Skew:                           0.515   Prob(JB):                     1.30e-43\n",
       "Kurtosis:                       4.590   Cond. No.                         223.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit per-at-bats model\n",
    "model3 = smf.ols('runs ~ singles + doubles + triples + HR + BB + SO', \n",
    "                 data = hitting_rates_df).fit()\n",
    "\n",
    "# Show model summary\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. \n",
    "The adjusted R-squared is considerably less than the non-rate based model at .641. This could be more reasonable than an R-squared of .959 given that a player's ability to score is depedent on the team around them as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 0.0\n",
      "RMSE = 0.018\n"
     ]
    }
   ],
   "source": [
    "# Define predictor data frame\n",
    "X = hitting_rates_df.drop(columns = 'runs')\n",
    "\n",
    "# Define outcome data frame\n",
    "Y = hitting_rates_df['runs']\n",
    "\n",
    "# Split hitting rates into training and testing data\n",
    "X_train, X_test, Y_train, Y_test = \\\n",
    "  train_test_split(X, Y, test_size = 0.30, random_state =328)\n",
    "\n",
    "# fit model\n",
    "fit = LinearRegression().fit(X_train, Y_train)\n",
    "\n",
    "# Predict test data \n",
    "predicted_y = fit.predict(X_test)\n",
    "\n",
    "# Calculate mse\n",
    "mse = mean_squared_error(Y_test, predicted_y)\n",
    "\n",
    "# calculate rmse \n",
    "rmse = math.sqrt(mse)\n",
    "\n",
    "# Print model metrics\n",
    "print(\"MSE =\", round(mse, 3))\n",
    "print(\"RMSE =\", round(rmse, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 0.001\n",
      "RMSE = 0.026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1320"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in 2022 data\n",
    "players_2022 = pd.read_csv(\"players_2022.csv\")\n",
    "\n",
    "hitting_2022_df = players_2022.drop(columns = 'playerID')\n",
    "\n",
    "X22 = hitting_2022_df.drop(columns = 'runs')\n",
    "Y22 = hitting_2022_df['runs']\n",
    "\n",
    "# Split 2022 hitting rates into training and testing data\n",
    "X22_train, X22_test, Y22_train, Y22_test = \\\n",
    "    train_test_split(X22, Y22, test_size = .30, random_state = 234)\n",
    "\n",
    "# Fit model on 2022 training data\n",
    "fit22 = LinearRegression().fit(X22_train, Y22_train)\n",
    "\n",
    "# Predict test data\n",
    "predicted_y22 = fit22.predict(X22_test)\n",
    "\n",
    "# Calculate mse\n",
    "mse22 = mean_squared_error(Y22_test, predicted_y22)\n",
    "\n",
    "# calculate rmse \n",
    "rmse22 = math.sqrt(mse22)\n",
    "\n",
    "# Print model metrics\n",
    "print(\"MSE =\", round(mse22, 3))\n",
    "print(\"RMSE =\", round(rmse22, 3))\n",
    "len(Y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. \n",
    "The 2022 model peformed .008 runs per-at-bat worse than the hall-of-fame data set. This could be explained by a few things. First, there are only 558 data points for the 2022 data and 1,320 for the hall-of-fame data so there is less data to train on for 2022 potentially explaing the loss in RMSE. There are also differences in style played that could give different dynamics for a long term data set. For example, steroid testing began in 2003 having an impact in the amounts of runs scored. This could have an impact on the relationship of runs and hits given that the data includes 10 years of steroid era baseball. One final difference is that the presence of hall-of-fame eligibility in the hall-of-fame data set means that players played for at least 10 years. The 2022 data will have outlier playeres with very few at-bats making it harder to predict for these players. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean runs per-at-bat HOF = 0.134\n",
      "Mean runs per-at-bat 2022 = 0.123\n",
      "T-statistic = 7.050031609009365\n",
      "P-value = 2.504267264381346e-12\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean runs per-at-bat for hof data\n",
    "mean_runs_hof = np.mean(hitting_rates_df['runs'])\n",
    "\n",
    "# Calculate mean runs per-at-bat for 2022 players\n",
    "mean_runs_2022 = np.mean(players_2022['runs'])\n",
    "\n",
    "# Print mean results\n",
    "print(\"Mean runs per-at-bat HOF =\", round(mean_runs_hof, 3))\n",
    "print(\"Mean runs per-at-bat 2022 =\", round(mean_runs_2022, 3))\n",
    "\n",
    "# Conduct independent t-test\n",
    "t_stat, p_value = stats.ttest_ind(hitting_rates_df['runs'], players_2022['runs'])\n",
    "\n",
    "# Print t-test results\n",
    "print(\"T-statistic =\", t_stat)\n",
    "print(\"P-value =\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a p-value << .001, we can conclude that there is a statistically significant difference between runs-at-bat for hall-of-fame eligible players when compared to 2022 players. The mean difference is .011 runs per-at-bat. This is sensible considering the length of time played by hall-of-fame eligible players. To be able to play for 10+ years in the MLB, it would stand to reason that you have demonstrated some competence while players from any given season will include rookies and players who will not last long in the league. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
